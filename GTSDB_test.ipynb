{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import pathlib\n",
    "import random as rn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Open the PPM image file\n",
    "image = Image.open('00002.ppm')\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize(img):\n",
    "    #print(type(img), img.shape)\n",
    "    img1=np.uint8(cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX))\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img = clahe.apply(img1)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = tf.expand_dims(img, axis=-1)\n",
    "    img = np.array(img)\n",
    "    img = img.astype(np.float64)\n",
    "    #print(type(img), img.shape)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/senti/Desktop/GTSDB'\n",
    "train_path = 'C:/Users/senti/Desktop/GTSDB/Train'\n",
    "test_path = 'C:/Users/senti/Desktop/GTSDB/Test/'\n",
    "height = 32\n",
    "width = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 150\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = { 0:'Speed limit (20km/h)',\n",
    "            1:'Speed limit (30km/h)', \n",
    "            2:'Speed limit (50km/h)', \n",
    "            3:'Speed limit (60km/h)', \n",
    "            4:'Speed limit (70km/h)', \n",
    "            5:'Speed limit (80km/h)', \n",
    "            6:'End of speed limit (80km/h)', \n",
    "            7:'Speed limit (100km/h)', \n",
    "            8:'Speed limit (120km/h)', \n",
    "            9:'No passing', \n",
    "            10:'No passing veh over 3.5 tons', \n",
    "            11:'Right-of-way at intersection', \n",
    "            12:'Priority road', \n",
    "            13:'Yield', \n",
    "            14:'Stop', \n",
    "            15:'No vehicles', \n",
    "            16:'Veh > 3.5 tons prohibited', \n",
    "            17:'No entry', \n",
    "            18:'General caution', \n",
    "            19:'Dangerous curve left', \n",
    "            20:'Dangerous curve right', \n",
    "            21:'Double curve', \n",
    "            22:'Bumpy road', \n",
    "            23:'Slippery road', \n",
    "            24:'Road narrows on the right', \n",
    "            25:'Road work', \n",
    "            26:'Traffic signals', \n",
    "            27:'Pedestrians', \n",
    "            28:'Children crossing', \n",
    "            29:'Bicycles crossing', \n",
    "            30:'Beware of ice/snow',\n",
    "            31:'Wild animals crossing', \n",
    "            32:'End speed + passing limits', \n",
    "            33:'Turn right ahead', \n",
    "            34:'Turn left ahead', \n",
    "            35:'Ahead only', \n",
    "            36:'Go straight or right', \n",
    "            37:'Go straight or left', \n",
    "            38:'Keep right', \n",
    "            39:'Keep left', \n",
    "            40:'Roundabout mandatory', \n",
    "            41:'End of no passing', \n",
    "            42:'End no passing veh > 3.5 tons' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms.functional import equalize\n",
    "\n",
    "# Image transformations for train and test datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # Convert to grayscale\n",
    "    transforms.Resize((height, width)),  # Resize images\n",
    "    transforms.Lambda(lambda img: equalize(img)),  # Equalize images\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),  # Rescale to range [-1, 1]\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.ImageFolder(train_path, transform=transform)\n",
    "\n",
    "# Split into training and validation sets (80/20 split)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For train dataset\n",
    "train_labels = [label for _, label in train_dataset]\n",
    "\n",
    "# For validation dataset\n",
    "val_labels = [label for _, label in val_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_set = set(train_labels)\n",
    "unique_list = (list(list_set))\n",
    "\n",
    "print(unique_list)\n",
    "unique_list.append(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(3,4)\n",
    "fig.set_size_inches(16,12)\n",
    "img,y = train_dataset.next()\n",
    "for i in range(3):\n",
    "    for j in range (4):\n",
    "        l=rn.randint(0,batch_size-1)\n",
    "        label = classes[int(list(train_dataset.class_indices.keys())[np.argmax(y[l])])]\n",
    "        ax[i,j].imshow(img[l])\n",
    "        ax[i,j].set_title(label)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import tensorboard\n",
    "import tensorboardX\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nni\n",
    "from nni.nas.nn.pytorch import ModelSpace, LayerChoice, MutableConv2d, MutableBatchNorm2d, MutableReLU\n",
    "from pytorch_lightning import Trainer\n",
    "from nni.nas.evaluator.pytorch import Lightning, ClassificationModule, Trainer\n",
    "from nni.nas.experiment import NasExperiment\n",
    "from nni.nas.space import model_context\n",
    "from nni.nas.hub.pytorch import DARTS\n",
    "from nni.nas.strategy import DARTS as DartsStrategy\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from nni.nas.experiment import NasExperiment\n",
    "from nni.nas.evaluator import FunctionalEvaluator\n",
    "from nni.nas.evaluator import FunctionalEvaluator\n",
    "import nni.nas.strategy as strategy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "#from ops import AvgPool,DilConv,SepConv\n",
    "import genotypes\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "from tqdm import tqdm\n",
    "from nni.nas.nn.pytorch import LayerChoice, ModelSpace,ValueChoice\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from torchvision import datasets, transforms\n",
    "from nni.nas.evaluator.pytorch import Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    def __init__(self, drop_prob=0.0):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.drop_prob == 0. or not self.training:\n",
    "            return x\n",
    "        keep_prob = 1 - self.drop_prob\n",
    "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # broadcast across channels\n",
    "        random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
    "        random_tensor.floor_()  # binarize\n",
    "        return x.div(keep_prob) * random_tensor  # scale output to maintain expectations\n",
    "\n",
    "    def set_drop_prob(self, drop_prob):\n",
    "        self.drop_prob = drop_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SepConv(nn.Module):\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, padding, affine=True):\n",
    "        super(SepConv, self).__init__()\n",
    "        self.op = nn.Sequential(\n",
    "            nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, padding=padding, groups=C_in),  \n",
    "            nn.Conv2d(C_in, C_in, kernel_size=1, padding=0),  \n",
    "            nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, padding=padding, groups=C_in), \n",
    "            nn.Conv2d(C_in, C_out, kernel_size=1, padding=0),  \n",
    "            nn.BatchNorm2d(C_out, affine=affine),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDARTSSpaceK3(ModelSpace):\n",
    "    def __init__(self, input_channels, channels, num_classes, layers, verbose):\n",
    "        super(CustomDARTSSpaceK3, self).__init__()\n",
    "        #self.first_iter = True\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.drop_path_prob = 0.0\n",
    "        self.drop_path = DropPath(self.drop_path_prob)\n",
    "        self.preliminary_layer = nn.Conv2d(3, 8, kernel_size=3, padding=0, bias=False)\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.layer1_conv1=nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1, groups=8)\n",
    "        self.layer1_conv2=nn.Conv2d(8, 8, kernel_size=1, padding=0)\n",
    "        self.layer1_conv3=nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1, groups=8)\n",
    "        self.layer1_conv4=nn.Conv2d(8, 64, kernel_size=1, padding=0)\n",
    "        self.layer1_bn=nn.BatchNorm2d(64, affine=True)\n",
    "        self.layer1_relu=nn.ReLU(inplace=True)\n",
    "\n",
    "        \n",
    "        self.layer2_conv1=nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, groups=64)\n",
    "        self.layer2_conv2=nn.Conv2d(64, 64, kernel_size=1, padding=0)\n",
    "        self.layer2_conv3=nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, groups=64)\n",
    "        self.layer2_conv4=nn.Conv2d(64, 2, kernel_size=1, padding=0)\n",
    "        self.layer2_bn=nn.BatchNorm2d(2, affine=True)\n",
    "        self.layer2_relu=nn.ReLU(inplace=True)  \n",
    "\n",
    "        \n",
    "        self.layer3_conv1=nn.Conv2d(2, 2, kernel_size=3, stride=1, padding=1, groups=2)\n",
    "        self.layer3_conv2=nn.Conv2d(2, 2, kernel_size=1, padding=0)\n",
    "        self.layer3_conv3=nn.Conv2d(2, 2, kernel_size=3, stride=1, padding=1, groups=2)\n",
    "        self.layer3_conv4=nn.Conv2d(2, 2, kernel_size=1, padding=0)\n",
    "        self.layer3_bn=nn.BatchNorm2d(2, affine=True)\n",
    "        self.layer3_relu=nn.ReLU(inplace=True)  \n",
    "\n",
    "        \n",
    "        self.layer4_conv1=nn.Conv2d(2, 2, kernel_size=3, stride=1, padding=1, groups=2)\n",
    "        self.layer4_conv2=nn.Conv2d(2, 2, kernel_size=1, padding=0)\n",
    "        self.layer4_conv3=nn.Conv2d(2, 2, kernel_size=3, stride=1, padding=1, groups=2)\n",
    "        self.layer4_conv4=nn.Conv2d(2, 2, kernel_size=1, padding=0)\n",
    "        self.layer4_bn=nn.BatchNorm2d(2, affine=True)\n",
    "        self.layer4_relu=nn.ReLU(inplace=True)  \n",
    "\n",
    "        \n",
    "        self.layer5_conv1=nn.Conv2d(2, 2, kernel_size=3, stride=1, padding=1, groups=2)\n",
    "        self.layer5_conv2=nn.Conv2d(2, 2, kernel_size=1, padding=0)\n",
    "        self.layer5_conv3=nn.Conv2d(2, 2, kernel_size=3, stride=1, padding=1, groups=2)\n",
    "        self.layer5_conv4=nn.Conv2d(2, 22, kernel_size=1, padding=0)\n",
    "        self.layer5_bn=nn.BatchNorm2d(22, affine=True)\n",
    "        self.layer5_relu=nn.ReLU(inplace=True)  \n",
    "\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d((2, 2))\n",
    "        self.fc1 = nn.Linear(198, 128) \n",
    "        self.fc2 = nn.Linear(128, 64) \n",
    "        self.fc3 = nn.Linear(64, 32)  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.classifier = nn.Linear(32, num_classes)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal_(m.weight, 0, 0.01)\n",
    "                init.constant_(m.bias, 0)\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.preliminary_layer(x)\n",
    "        # Unroll layer1\n",
    "        x = self.layer1_conv1(x)\n",
    "        x = self.layer1_conv2(x)\n",
    "        x = self.layer1_conv3(x)\n",
    "        x = self.layer1_conv4(x)\n",
    "        x = self.layer1_bn(x)\n",
    "        x = self.layer1_relu(x)\n",
    "        x = self.drop_path(x)  \n",
    "        \n",
    "        # Unroll layer2\n",
    "        x = self.layer2_conv1(x)\n",
    "        x = self.layer2_conv2(x)\n",
    "        x = self.layer2_conv3(x)\n",
    "        x = self.layer2_conv4(x)\n",
    "        x = self.layer2_bn(x)\n",
    "        x = self.layer2_relu(x)\n",
    "        x = self.drop_path(x) \n",
    "        \n",
    "        # First AvgPool after layer2\n",
    "        x = nn.AvgPool2d(kernel_size=2, stride=2)(x)\n",
    "        \n",
    "        # Unroll layer3\n",
    "        x = self.layer3_conv1(x)\n",
    "        x = self.layer3_conv2(x)\n",
    "        x = self.layer3_conv3(x)\n",
    "        x = self.layer3_conv4(x)\n",
    "        x = self.layer3_bn(x)\n",
    "        x = self.layer3_relu(x)\n",
    "        x = self.drop_path(x)  \n",
    "        \n",
    "        # Unroll layer4\n",
    "        x = self.layer4_conv1(x)\n",
    "        x = self.layer4_conv2(x)\n",
    "        x = self.layer4_conv3(x)\n",
    "        x = self.layer4_conv4(x)\n",
    "        x = self.layer4_bn(x)\n",
    "        x = self.layer4_relu(x)\n",
    "        x = self.drop_path(x)  \n",
    "        \n",
    "        # Second AvgPool after layer4\n",
    "        x = nn.AvgPool2d(kernel_size=2, stride=2)(x)\n",
    "        \n",
    "        # Unroll layer5\n",
    "        x = self.layer5_conv1(x)\n",
    "        x = self.layer5_conv2(x)\n",
    "        x = self.layer5_conv3(x)\n",
    "        x = self.layer5_conv4(x)\n",
    "        x = self.layer5_bn(x)\n",
    "        x = self.layer5_relu(x)\n",
    "        x = self.drop_path(x)  \n",
    "        \n",
    "        x =  nn.AvgPool2d(kernel_size=2, stride =2)(x)\n",
    "        if self.verbose == 1 :\n",
    "            print(f'After adaptive pooling: {x.shape}')\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        if self.verbose == 1 :\n",
    "            print(f'After flattening: {x.shape}')\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x= self.relu(x)\n",
    "        if self.verbose == 1 :\n",
    "            print(f'After fc1: {x.shape}')\n",
    "        x = self.fc2(x)\n",
    "        x= self.relu(x)\n",
    "        if self.verbose == 1 :\n",
    "            print(f'After fc2: {x.shape}')\n",
    "        x = self.fc3(x)\n",
    "        x= self.relu(x)\n",
    "        if self.verbose == 1 :\n",
    "            print(f'After fc3: {x.shape}')\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        if self.verbose == 1 :\n",
    "            print(f'After classifier: {x.shape}')\n",
    "        #self.first_iter = False\n",
    "        return x\n",
    "\n",
    "\n",
    "    def set_drop_path_prob(self, drop_path_prob):\n",
    "        self.drop_path_prob = drop_path_prob\n",
    "        self.drop_path.set_drop_prob(drop_path_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "import torch\n",
    "\n",
    "def get_cifar10_dataset(train: bool = True, cutout: bool = False):\n",
    "    CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\n",
    "    CIFAR_STD = [0.24703233, 0.24348505, 0.26158768]\n",
    "\n",
    "    if train:\n",
    "        transform_list = [\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(CIFAR_MEAN, CIFAR_STD),\n",
    "        ]\n",
    "        # Define or remove cutout_transform if not needed\n",
    "        if cutout:\n",
    "            transform_list.append(cutout_transform)  \n",
    "        transform = transforms.Compose(transform_list)\n",
    "    else:\n",
    "        # No data augmentation for validation/testing\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(CIFAR_MEAN, CIFAR_STD),\n",
    "        ])\n",
    "\n",
    "    dataset = datasets.CIFAR10(root='./data', train=train, download=True, transform=transform)\n",
    "    return dataset\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "validation_split = 0.5\n",
    "\n",
    "# Get the full training dataset\n",
    "train_data = get_cifar10_dataset(train=True)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(len(train_data) * (1 - validation_split))\n",
    "valid_size = len(train_data) - train_size\n",
    "\n",
    "train_dataset, valid_dataset = random_split(train_data, [train_size, valid_size])\n",
    "\n",
    "# DataLoader for training set\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size,\n",
    "    shuffle=True, pin_memory=True, num_workers=6\n",
    ")\n",
    "\n",
    "# DataLoader for validation set\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, batch_size=batch_size,\n",
    "    shuffle=False, pin_memory=True, num_workers=18\n",
    ")\n",
    "\n",
    "# If needed, load the test set\n",
    "test_data = get_cifar10_dataset(train=False)\n",
    "test_loader = DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    shuffle=False, pin_memory=True, num_workers=18\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Initialize optimizer, criterion, and scheduler (optional)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,  # Reduced learning rate for more stable training\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-07,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # Optional scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Move the model to the device (GPU if available)\n",
    "    model.train()  # Set the model to training mode\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Dynamically set DropPath probability (if your model supports it)\n",
    "        drop_prob = 0.2 * (epoch / num_epochs)  # Adjust the scale as needed\n",
    "        model.set_drop_path_prob(drop_prob)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(progress_bar):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            \n",
    "            # Gradient clipping to prevent instability\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            # Gradient accumulation (if using)\n",
    "            if (i + 1) % 4 == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Update tqdm description with current loss\n",
    "            progress_bar.set_postfix(loss=running_loss / (i+1))\n",
    "\n",
    "        # Step scheduler (optional)\n",
    "        scheduler.step()\n",
    "\n",
    "        if epoch%9 == 0:\n",
    "            val_accuracy = evaluate_model(model, valid_loader, device)\n",
    "            print(f\"Validation accuracy after epoch {epoch+1}: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "def evaluate_model(model, valid_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "    \n",
    "    return correct / len(valid_loader.dataset)\n",
    "\n",
    "# Example of running the training\n",
    "train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, valid_loader, criterion):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()  # Move data to GPU if available\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Loss: {running_loss / len(valid_loader):.4f}')\n",
    "    print(f'Validation Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "validate_model(model, valid_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
