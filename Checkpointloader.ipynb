{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import tensorboard\n",
    "import tensorboardX\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nni\n",
    "from nni.nas.nn.pytorch import ModelSpace, LayerChoice, MutableConv2d, MutableBatchNorm2d, MutableReLU\n",
    "from pytorch_lightning import Trainer\n",
    "from nni.nas.evaluator.pytorch import Lightning, ClassificationModule, Trainer\n",
    "from nni.nas.experiment import NasExperiment\n",
    "from nni.nas.space import model_context\n",
    "from nni.nas.hub.pytorch import DARTS\n",
    "from nni.nas.strategy import DARTS as DartsStrategy\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from nni.nas.experiment import NasExperiment\n",
    "from nni.nas.evaluator import FunctionalEvaluator\n",
    "from nni.nas.evaluator import FunctionalEvaluator\n",
    "import nni.nas.strategy as strategy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "#from ops import AvgPool,DilConv,SepConv\n",
    "import genotypes\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "from tqdm import tqdm\n",
    "from nni.nas.nn.pytorch import LayerChoice, ModelSpace,ValueChoice\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from torchvision import datasets, transforms\n",
    "from nni.nas.evaluator.pytorch import Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SepConv(nn.Module):\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, padding, affine=True):\n",
    "        super(SepConv, self).__init__()\n",
    "        self.op = nn.Sequential(\n",
    "            MutableConv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            MutableConv2d(C_in, C_in, kernel_size=1, padding=0),\n",
    "            MutableConv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            MutableConv2d(C_in, C_out, kernel_size=1, padding=0),\n",
    "            MutableBatchNorm2d(C_out,affine=affine),\n",
    "            MutableReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.op(x)\n",
    "        \n",
    "                \n",
    "        \n",
    "class PhotonicSigmoid(nn.Module):\n",
    "    def forward(self, x):\n",
    "        tmp = torch.exp((x - 0.145) / 0.073)\n",
    "        tmp = 1.005 + (0.06 - 1.005) / (1 + tmp)\n",
    "        return tmp.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDARTSSpaceK3(ModelSpace):\n",
    "    def __init__(self, input_channels, channels, num_classes, layers, verbose):\n",
    "        super(CustomDARTSSpaceK3, self).__init__()\n",
    "        #self.first_iter = True\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.drop_path_prob = 0.0  \n",
    "        self.preliminary_layer = nn.Conv2d(3, 8, kernel_size=3, padding=0, bias=False)\n",
    "        self.verbose = verbose\n",
    "\n",
    "        layer1_in = 8\n",
    "        layer1_out = nni.choice('layer1_out_channels', [2,4,8,16,32,64])\n",
    "        layer2_out= nni.choice('layer2_out_channels', [2,4,8,16,32,64])\n",
    "        layer3_out= nni.choice('layer3_out_channels', [2,4,8,16,32,64])\n",
    "        layer4_out= nni.choice('layer4_out_channels', [2,4,8,16,32,64])\n",
    "        layer5_out = 22 \n",
    "\n",
    "        \n",
    "        layer1 = LayerChoice([\n",
    "              SepConv(8, layer1_out, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                MutableConv2d(8, layer1_out, kernel_size=1),\n",
    "                MutableBatchNorm2d(layer1_out),\n",
    "                MutableReLU()\n",
    "            ),   \n",
    "            nn.Sequential(\n",
    "                MutableConv2d(8, layer1_out, kernel_size=1),\n",
    "                nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                MutableBatchNorm2d(layer1_out),\n",
    "                MutableReLU()\n",
    "            )\n",
    "        ], label='layer_1')\n",
    "        self.layers.append(layer1)\n",
    "        \n",
    "        layer2 = LayerChoice([\n",
    "            SepConv(layer1_out, layer2_out, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                MutableConv2d(layer1_out, layer2_out, kernel_size=1),\n",
    "                MutableBatchNorm2d(layer2_out),\n",
    "                MutableReLU()\n",
    "            ),   \n",
    "            nn.Sequential(\n",
    "                MutableConv2d(layer1_out, layer2_out, kernel_size=1),\n",
    "                nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                MutableBatchNorm2d(layer2_out),\n",
    "                MutableReLU()\n",
    "            )\n",
    "        ], label='layer_2')\n",
    "        self.layers.append(layer2)\n",
    "        \n",
    "        layer3 = LayerChoice([\n",
    "            SepConv(layer2_out, layer3_out, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                MutableConv2d(layer2_out, layer3_out, kernel_size=1),\n",
    "                MutableBatchNorm2d(layer3_out),\n",
    "                MutableReLU()\n",
    "            ),   \n",
    "            nn.Sequential(\n",
    "                MutableConv2d(layer2_out, layer3_out, kernel_size=1),\n",
    "                nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                MutableBatchNorm2d(layer3_out),\n",
    "                MutableReLU()\n",
    "            )\n",
    "        ], label='layer_3')\n",
    "        self.layers.append(layer3)\n",
    "        \n",
    "        layer4 = LayerChoice([\n",
    "            SepConv(layer3_out, layer4_out, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                MutableConv2d(layer3_out, layer4_out, kernel_size=1),\n",
    "                MutableBatchNorm2d(layer4_out),\n",
    "                MutableReLU()\n",
    "            ),   \n",
    "            nn.Sequential(\n",
    "                MutableConv2d(layer3_out, layer4_out, kernel_size=1),\n",
    "                nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                MutableBatchNorm2d(layer4_out),\n",
    "                MutableReLU()\n",
    "            )\n",
    "        ], label='layer_4')\n",
    "        self.layers.append(layer4)\n",
    "        \n",
    "        layer5 = LayerChoice([\n",
    "            SepConv(layer4_out, layer5_out, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                MutableConv2d(layer4_out, layer5_out, kernel_size=1),\n",
    "                MutableBatchNorm2d(layer5_out),\n",
    "                MutableReLU()\n",
    "            ),   \n",
    "            nn.Sequential(\n",
    "                MutableConv2d(layer4_out, layer5_out, kernel_size=1),\n",
    "                nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                MutableBatchNorm2d(layer5_out),\n",
    "                MutableReLU()\n",
    "            )\n",
    "        ], label='layer_5')\n",
    "        self.layers.append(layer5)\n",
    "        \n",
    "        # Ensure the number of inputs to fc1 is close to but not exceeding 200\n",
    "        self.pool = nn.AdaptiveAvgPool2d((2, 2))\n",
    "        self.fc1 = nn.Linear(198, 128) \n",
    "        self.fc2 = nn.Linear(128, 64) \n",
    "        self.fc3 = nn.Linear(64, 32)  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.classifier = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Kernel: 2\n",
    "        # Initial shape: 32x32\n",
    "        #print(f'Input shape: {x.shape}')\n",
    "        x = self.preliminary_layer(x)\n",
    "        # After preliminary layer: 31x31\n",
    "        if self.verbose == 1 :\n",
    "            print(f'After preliminary layer: {x.shape}')\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if self.verbose == 1 :\n",
    "                print(f'After layer {i+1}: {x.shape}')\n",
    "            \n",
    "            # Add a AvgPool2d layer after the third layer to reduce spatial dimensions\n",
    "            if i == 2 or i == 4:\n",
    "                x = nn.AvgPool2d(kernel_size=2, stride=2)(x)\n",
    "                if self.verbose == 1 :\n",
    "                    print(f'After avg pooling: {x.shape}')\n",
    "        \n",
    "\n",
    "        x =  nn.AvgPool2d(kernel_size=2, stride =2)(x)\n",
    "        if self.verbose == 1 :\n",
    "            print(f'After adaptive pooling: {x.shape}')\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        if self.verbose == 1 :\n",
    "            print(f'After flattening: {x.shape}')\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x= self.relu(x)\n",
    "        if self.verbose == 1 :\n",
    "            print(f'After fc1: {x.shape}')\n",
    "        x = self.fc2(x)\n",
    "        x= self.relu(x)\n",
    "        if self.verbose == 1 :\n",
    "            print(f'After fc2: {x.shape}')\n",
    "        x = self.fc3(x)\n",
    "        x= self.relu(x)\n",
    "        if self.verbose == 1 :\n",
    "            print(f'After fc3: {x.shape}')\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        if self.verbose == 1 :\n",
    "            print(f'After classifier: {x.shape}')\n",
    "        #self.first_iter = False\n",
    "        return x\n",
    "\n",
    "    def set_drop_path_prob(self, drop_path_prob):\n",
    "        self.drop_path_prob = drop_path_prob\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'set_drop_path_prob'):\n",
    "                layer.set_drop_path_prob(drop_path_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './checkpoints/best-checkpoint-v5.ckpt'\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "\n",
    "model_checkpoint = CustomDARTSSpaceK3(input_channels=3, channels=64, num_classes=10, layers=5,verbose =0)\n",
    "\n",
    "model_state_dict = model_checkpoint.state_dict()\n",
    "pretrained_state_dict = checkpoint['state_dict']\n",
    "\n",
    "filtered_state_dict = {k: v for k, v in pretrained_state_dict.items() if k in model_state_dict}\n",
    "\n",
    "model_state_dict.update(filtered_state_dict)\n",
    "\n",
    "model_checkpoint.load_state_dict(model_state_dict)\n",
    "\n",
    "\n",
    "if 'global_step' in checkpoint:\n",
    "    print(\"Global Step:\", checkpoint['global_step'])\n",
    "\n",
    "if 'callbacks' in checkpoint and isinstance(checkpoint['callbacks'], dict):\n",
    "    for key, callback in checkpoint['callbacks'].items():\n",
    "        if isinstance(callback, dict) and 'best_model_score' in callback:\n",
    "            print(\"Best Model Score (Train Accuracy):\", callback['best_model_score'].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_checkpoint = model_checkpoint.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)  \n",
    "\n",
    "if 'optimizer_state_dict' in checkpoint:\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "model_checkpoint.train()\n",
    "\n",
    "def continue_training(model, train_loader, criterion, optimizer, num_epochs, start_epoch=0):\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "# Continue training the model\n",
    "continue_training(model_checkpoint, train_loader, criterion, optimizer, num_epochs=600, start_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
